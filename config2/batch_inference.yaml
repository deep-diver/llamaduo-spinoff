ft_model_id: klcsp/gemma7b-gpt4o_1k_closedqa-fft # kasa-lora/llama3.1-8b-gpt4o_100k_coding-fft 
ft_model_revision: main
ft_model_config_path: config2/gemma7b_fft_summarize.yaml
ft-model-gen-config-path: config/ft_gen_configs.yaml

test_ds_id: llama-duo/coverage_dataset
test_ds_split: test_closed_qa

batch_infer_data_preprocess_bs: 16
inference_bs: 8
repeat: 4

push_lm_responses_to_hf_hub: true
lm_response_ds_id: klcsp/closedqa-response
lm_response_ds_split: gemma7b_fft 
lm-response-append: true
